{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","authorship_tag":"ABX9TyPodLNyRgm26k1zK2yhWuhR"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":4,"metadata":{"id":"AtPUrNI8a-4U","executionInfo":{"status":"ok","timestamp":1721819694938,"user_tz":-180,"elapsed":3,"user":{"displayName":"Dominic Ocharo","userId":"01762039169451979646"}}},"outputs":[],"source":["# !pip install transformers pillow\n","# !pip install einops timm flash_attn"]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Iymc2BfYa_h9","executionInfo":{"status":"ok","timestamp":1721819700285,"user_tz":-180,"elapsed":3485,"user":{"displayName":"Dominic Ocharo","userId":"01762039169451979646"}},"outputId":"cbe72d43-23b1-4747-e4d9-b62aad2ed742"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}]},{"cell_type":"code","source":["from transformers import AutoProcessor, AutoModelForCausalLM\n","from PIL import Image\n","import requests\n","import numpy as np\n","import copy\n","import os\n","\n","# Initialize the model and processor\n","model_id = 'microsoft/Florence-2-large'\n","model = AutoModelForCausalLM.from_pretrained(model_id, trust_remote_code=True).eval()\n","processor = AutoProcessor.from_pretrained(model_id, trust_remote_code=True)"],"metadata":{"id":"VO3udFMia_kT","executionInfo":{"status":"ok","timestamp":1721819734154,"user_tz":-180,"elapsed":32282,"user":{"displayName":"Dominic Ocharo","userId":"01762039169451979646"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"f238138e-b97a-4387-8df1-81007eabd6ac"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:89: UserWarning: \n","The secret `HF_TOKEN` does not exist in your Colab secrets.\n","To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n","You will be able to reuse this secret in all of your notebooks.\n","Please note that authentication is recommended but still optional to access public models or datasets.\n","  warnings.warn(\n"]}]},{"cell_type":"markdown","source":["## Single Image"],"metadata":{"id":"-vEdk0wg0WwO"}},{"cell_type":"code","source":["def preprocess_image(image_path):\n","    image = Image.open(image_path).convert(\"RGB\")\n","    image_array = np.array(image)\n","    return image_array\n","\n","def run_example(task_prompt, image_path, text_input=None):\n","    if text_input is None:\n","        prompt = task_prompt\n","    else:\n","        prompt = task_prompt + text_input\n","\n","    # Ensure the image is in the correct format\n","    image_array = preprocess_image(image_path)\n","    inputs = processor(text=prompt, images=image_array, return_tensors=\"pt\")\n","\n","    generated_ids = model.generate(\n","        input_ids=inputs['input_ids'],\n","        pixel_values=inputs['pixel_values'],\n","        max_new_tokens=1024,\n","        early_stopping=False,\n","        num_beams=3,\n","        do_sample=False,\n","    )\n","\n","    generated_text = processor.batch_decode(generated_ids, skip_special_tokens=False)[0]\n","    parsed_answer = processor.post_process_generation(\n","        generated_text,\n","        task=task_prompt,\n","        image_size=(image_array.shape[1], image_array.shape[0])  # width, height\n","    )\n","\n","    return parsed_answer\n","\n","def save_results(image_path, results, output_folder):\n","    image_name = os.path.splitext(os.path.basename(image_path))[0]\n","    txt_filename = os.path.join(output_folder, image_name + '.txt')\n","\n","    # Preprocess image to get dimensions\n","    image_array = preprocess_image(image_path)\n","\n","    # Extract bounding box information\n","    bboxes = results['<DENSE_REGION_CAPTION>']['bboxes']\n","    labels = results['<DENSE_REGION_CAPTION>']['labels']\n","\n","    # Open the text file for writing\n","    with open(txt_filename, 'w') as f:\n","        for label, bbox in zip(labels, bboxes):\n","            x_min, y_min, x_max, y_max = bbox\n","            width = x_max - x_min\n","            height = y_max - y_min\n","            x_center = x_min + width / 2\n","            y_center = y_min + height / 2\n","\n","            # Normalize coordinates\n","            x_center /= image_array.shape[1]\n","            y_center /= image_array.shape[0]\n","            width /= image_array.shape[1]\n","            height /= image_array.shape[0]\n","\n","            # Write the label and normalized bounding box to the file\n","            f.write(f\"{label} {x_center:.6f} {y_center:.6f} {width:.6f} {height:.6f}\\n\")\n","\n","task_prompt = '<DENSE_REGION_CAPTION>'\n","\n","image_path = '/content/drive/MyDrive/autolabel/car.jpg'\n","output_folder = '/content/drive/MyDrive/autolabel'\n","os.makedirs(output_folder, exist_ok=True)\n","\n","results = run_example(task_prompt, image_path)\n","save_results(image_path, results, output_folder)\n"],"metadata":{"id":"ryme-ek3a_m9","executionInfo":{"status":"error","timestamp":1721819663223,"user_tz":-180,"elapsed":611,"user":{"displayName":"Dominic Ocharo","userId":"01762039169451979646"}},"colab":{"base_uri":"https://localhost:8080/","height":211},"outputId":"c88a660d-a8cc-4aac-efb6-992fe5c46914"},"execution_count":2,"outputs":[{"output_type":"error","ename":"NameError","evalue":"name 'os' is not defined","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-2-c6ceeb28fabd>\u001b[0m in \u001b[0;36m<cell line: 67>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[0mimage_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'/content/drive/MyDrive/autolabel/car.jpg'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m \u001b[0moutput_folder\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'/content/drive/MyDrive/autolabel'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmakedirs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_folder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexist_ok\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrun_example\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtask_prompt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimage_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'os' is not defined"]}]},{"cell_type":"markdown","source":["## Multiple Images in a Folder"],"metadata":{"id":"VWRmZA5k0UU-"}},{"cell_type":"code","source":["from transformers import AutoProcessor, AutoModelForCausalLM\n","from PIL import Image\n","import numpy as np\n","import os\n","\n","# Initialize the model and processor\n","model_id = 'microsoft/Florence-2-large'\n","model = AutoModelForCausalLM.from_pretrained(model_id, trust_remote_code=True).eval()\n","processor = AutoProcessor.from_pretrained(model_id, trust_remote_code=True)\n","\n","def preprocess_image(image_path):\n","    image = Image.open(image_path).convert(\"RGB\")\n","    image_array = np.array(image)\n","    return image_array\n","\n","def run_example(task_prompt, image_path, text_input=None):\n","    if text_input is None:\n","        prompt = task_prompt\n","    else:\n","        prompt = task_prompt + text_input\n","\n","    # Ensure the image is in the correct format\n","    image_array = preprocess_image(image_path)\n","    inputs = processor(text=prompt, images=image_array, return_tensors=\"pt\")\n","\n","    generated_ids = model.generate(\n","        input_ids=inputs['input_ids'],\n","        pixel_values=inputs['pixel_values'],\n","        max_new_tokens=1024,\n","        early_stopping=False,\n","        num_beams=3,\n","        do_sample=False,\n","    )\n","\n","    generated_text = processor.batch_decode(generated_ids, skip_special_tokens=False)[0]\n","    parsed_answer = processor.post_process_generation(\n","        generated_text,\n","        task=task_prompt,\n","        image_size=(image_array.shape[1], image_array.shape[0])  # width, height\n","    )\n","\n","    return parsed_answer\n","\n","def save_results(image_path, results, output_folder):\n","    image_name = os.path.splitext(os.path.basename(image_path))[0]\n","    txt_filename = os.path.join(output_folder, image_name + '.txt')\n","\n","    # Preprocess image to get dimensions\n","    image_array = preprocess_image(image_path)\n","\n","    # Extract bounding box information\n","    bboxes = results['<DENSE_REGION_CAPTION>']['bboxes']\n","    labels = results['<DENSE_REGION_CAPTION>']['labels']\n","\n","    # Open the text file for writing\n","    with open(txt_filename, 'w') as f:\n","        for label, bbox in zip(labels, bboxes):\n","            x_min, y_min, x_max, y_max = bbox\n","            width = x_max - x_min\n","            height = y_max - y_min\n","            x_center = x_min + width / 2\n","            y_center = y_min + height / 2\n","\n","            # Normalize coordinates\n","            x_center /= image_array.shape[1]\n","            y_center /= image_array.shape[0]\n","            width /= image_array.shape[1]\n","            height /= image_array.shape[0]\n","\n","            # Write the label and normalized bounding box to the file\n","            f.write(f\"{label} {x_center:.6f} {y_center:.6f} {width:.6f} {height:.6f}\\n\")\n","\n","def process_images_in_folder(input_folder, output_folder, task_prompt):\n","    # Create the output folder if it does not exist\n","    os.makedirs(output_folder, exist_ok=True)\n","\n","    # Iterate over all files in the input folder\n","    for filename in os.listdir(input_folder):\n","        if filename.lower().endswith(('.png', '.jpg', '.jpeg')):\n","            image_path = os.path.join(input_folder, filename)\n","            results = run_example(task_prompt, image_path)\n","            save_results(image_path, results, output_folder)\n","\n","task_prompt = '<DENSE_REGION_CAPTION>'\n","\n","input_folder = '/content/drive/MyDrive/autolabel/images'\n","output_folder = '/content/drive/MyDrive/autolabel/labels'\n","\n","process_images_in_folder(input_folder, output_folder, task_prompt)\n"],"metadata":{"id":"_iLN48h3cxj5","executionInfo":{"status":"error","timestamp":1721819590867,"user_tz":-180,"elapsed":36331,"user":{"displayName":"Dominic Ocharo","userId":"01762039169451979646"}},"colab":{"base_uri":"https://localhost:8080/","height":339},"outputId":"22c76c4b-ecea-43c4-a1fe-9b058aae7e2b"},"execution_count":5,"outputs":[{"output_type":"error","ename":"KeyboardInterrupt","evalue":"","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-5-98aa85d5f638>\u001b[0m in \u001b[0;36m<cell line: 89>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     87\u001b[0m \u001b[0moutput_folder\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'/content/drive/MyDrive/autolabel/labels'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 89\u001b[0;31m \u001b[0mprocess_images_in_folder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_folder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_folder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtask_prompt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m<ipython-input-5-98aa85d5f638>\u001b[0m in \u001b[0;36mprocess_images_in_folder\u001b[0;34m(input_folder, output_folder, task_prompt)\u001b[0m\n\u001b[1;32m     79\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mendswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'.png'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'.jpg'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'.jpeg'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m             \u001b[0mimage_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_folder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 81\u001b[0;31m             \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrun_example\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtask_prompt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimage_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     82\u001b[0m             \u001b[0msave_results\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_folder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-5-98aa85d5f638>\u001b[0m in \u001b[0;36mrun_example\u001b[0;34m(task_prompt, image_path, text_input)\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprocessor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mprompt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mimage_array\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_tensors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"pt\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m     generated_ids = model.generate(\n\u001b[0m\u001b[1;32m     27\u001b[0m         \u001b[0minput_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'input_ids'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m         \u001b[0mpixel_values\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'pixel_values'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m~/.cache/huggingface/modules/transformers_modules/microsoft/Florence-2-large/6bf179230dd8855083a51a5e11beb04aec1291fd/modeling_florence2.py\u001b[0m in \u001b[0;36mgenerate\u001b[0;34m(self, input_ids, inputs_embeds, pixel_values, **kwargs)\u001b[0m\n\u001b[1;32m   2794\u001b[0m                 \u001b[0minputs_embeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_mask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_merge_input_ids_with_image_features\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs_embeds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2795\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2796\u001b[0;31m         return self.language_model.generate(\n\u001b[0m\u001b[1;32m   2797\u001b[0m             \u001b[0minput_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2798\u001b[0m             \u001b[0minputs_embeds\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs_embeds\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/_contextlib.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    113\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mctx_factory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 115\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    116\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py\u001b[0m in \u001b[0;36mgenerate\u001b[0;34m(self, inputs, generation_config, logits_processor, stopping_criteria, prefix_allowed_tokens_fn, synced_gpus, assistant_model, streamer, negative_prompt_ids, negative_prompt_attention_mask, **kwargs)\u001b[0m\n\u001b[1;32m   1951\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1952\u001b[0m             \u001b[0;31m# 14. run beam sample\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1953\u001b[0;31m             result = self._beam_search(\n\u001b[0m\u001b[1;32m   1954\u001b[0m                 \u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1955\u001b[0m                 \u001b[0mbeam_scorer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py\u001b[0m in \u001b[0;36m_beam_search\u001b[0;34m(self, input_ids, beam_scorer, logits_processor, stopping_criteria, generation_config, synced_gpus, logits_warper, **model_kwargs)\u001b[0m\n\u001b[1;32m   2994\u001b[0m             \u001b[0mbeam_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbeam_outputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"next_beam_indices\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2995\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2996\u001b[0;31m             \u001b[0minput_ids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbeam_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbeam_next_tokens\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2997\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2998\u001b[0m             model_kwargs = self._update_model_kwargs_for_generation(\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"markdown","source":["## Multiple Images in a Folder with the Labels in a List"],"metadata":{"id":"vPOV_oDE0EaD"}},{"cell_type":"code","source":["def preprocess_image(image_path):\n","    image = Image.open(image_path).convert(\"RGB\")\n","    image_array = np.array(image)\n","    return image_array\n","\n","def run_example(task_prompt, image_path, text_input=None):\n","    if text_input is None:\n","        prompt = task_prompt\n","    else:\n","        prompt = task_prompt + text_input\n","\n","    # Ensure the image is in the correct format\n","    image_array = preprocess_image(image_path)\n","    inputs = processor(text=prompt, images=image_array, return_tensors=\"pt\")\n","\n","    generated_ids = model.generate(\n","        input_ids=inputs['input_ids'],\n","        pixel_values=inputs['pixel_values'],\n","        max_new_tokens=1024,\n","        early_stopping=False,\n","        num_beams=3,\n","        do_sample=False,\n","    )\n","\n","    generated_text = processor.batch_decode(generated_ids, skip_special_tokens=False)[0]\n","    parsed_answer = processor.post_process_generation(\n","        generated_text,\n","        task=task_prompt,\n","        image_size=(image_array.shape[1], image_array.shape[0])  # width, height\n","    )\n","\n","    return parsed_answer\n","\n","def save_results(image_path, results, output_folder, all_labels):\n","    image_name = os.path.splitext(os.path.basename(image_path))[0]\n","    txt_filename = os.path.join(output_folder, image_name + '.txt')\n","\n","    # Preprocess image to get dimensions\n","    image_array = preprocess_image(image_path)\n","\n","    # Extract bounding box information\n","    bboxes = results['<DENSE_REGION_CAPTION>']['bboxes']\n","    labels = results['<DENSE_REGION_CAPTION>']['labels']\n","\n","    # Update all_labels list with the labels from this image\n","    all_labels.extend(labels)\n","\n","    # Open the text file for writing\n","    with open(txt_filename, 'w') as f:\n","        for label, bbox in zip(labels, bboxes):\n","            x_min, y_min, x_max, y_max = bbox\n","            width = x_max - x_min\n","            height = y_max - y_min\n","            x_center = x_min + width / 2\n","            y_center = y_min + height / 2\n","\n","            # Normalize coordinates\n","            x_center /= image_array.shape[1]\n","            y_center /= image_array.shape[0]\n","            width /= image_array.shape[1]\n","            height /= image_array.shape[0]\n","\n","            # Write the label and normalized bounding box to the file\n","            f.write(f\"{label} {x_center:.6f} {y_center:.6f} {width:.6f} {height:.6f}\\n\")\n","\n","def process_images_in_folder(input_folder, output_folder, task_prompt):\n","    # Create the output folder if it does not exist\n","    os.makedirs(output_folder, exist_ok=True)\n","\n","    all_labels = []\n","\n","    # Iterate over all files in the input folder\n","    for filename in os.listdir(input_folder):\n","        if filename.lower().endswith(('.png', '.jpg', '.jpeg')):\n","            image_path = os.path.join(input_folder, filename)\n","            results = run_example(task_prompt, image_path)\n","            save_results(image_path, results, output_folder, all_labels)\n","\n","    # Print all unique labels detected\n","    unique_labels = list(set(all_labels))\n","    print(\"Unique labels detected:\", unique_labels)\n","\n","\n","task_prompt = '<DENSE_REGION_CAPTION>'\n","\n","input_folder = '/content/drive/MyDrive/autolabel/images'\n","output_folder = '/content/drive/MyDrive/autolabel/labels'\n","\n","process_images_in_folder(input_folder, output_folder, task_prompt)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":321},"id":"WmYoehQqhyoW","executionInfo":{"status":"error","timestamp":1721820590600,"user_tz":-180,"elapsed":42726,"user":{"displayName":"Dominic Ocharo","userId":"01762039169451979646"}},"outputId":"f0be23b5-4397-48bd-a33b-75dc16104841"},"execution_count":7,"outputs":[{"output_type":"error","ename":"FileNotFoundError","evalue":"[Errno 2] No such file or directory: '/content/drive/MyDrive/autolabel/images/14.jpeg'","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-7-4c4f05668ca9>\u001b[0m in \u001b[0;36m<cell line: 89>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     87\u001b[0m \u001b[0moutput_folder\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'/content/drive/MyDrive/autolabel/labels'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 89\u001b[0;31m \u001b[0mprocess_images_in_folder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_folder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_folder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtask_prompt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m<ipython-input-7-4c4f05668ca9>\u001b[0m in \u001b[0;36mprocess_images_in_folder\u001b[0;34m(input_folder, output_folder, task_prompt)\u001b[0m\n\u001b[1;32m     75\u001b[0m             \u001b[0mimage_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_folder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m             \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrun_example\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtask_prompt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimage_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 77\u001b[0;31m             \u001b[0msave_results\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_folder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mall_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     78\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m     \u001b[0;31m# Print all unique labels detected\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-7-4c4f05668ca9>\u001b[0m in \u001b[0;36msave_results\u001b[0;34m(image_path, results, output_folder, all_labels)\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m     \u001b[0;31m# Preprocess image to get dimensions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m     \u001b[0mimage_array\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpreprocess_image\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m     \u001b[0;31m# Extract bounding box information\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-7-4c4f05668ca9>\u001b[0m in \u001b[0;36mpreprocess_image\u001b[0;34m(image_path)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mpreprocess_image\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"RGB\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mimage_array\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mimage_array\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/PIL/Image.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(fp, mode, formats)\u001b[0m\n\u001b[1;32m   3225\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3226\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3227\u001b[0;31m         \u001b[0mfp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuiltins\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3228\u001b[0m         \u001b[0mexclusive_fp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3229\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/drive/MyDrive/autolabel/images/14.jpeg'"]}]},{"cell_type":"code","source":[],"metadata":{"id":"jkSpMn5yiGHY"},"execution_count":null,"outputs":[]}]}