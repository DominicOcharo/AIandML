{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Groq and Gradio for Image Moderation with LLaVA and Llama Guard 📷\n",
    "\n",
    "In this tutorial, we'll build an image moderation application powered by Groq for fast image analysis and content safety checking. We'll also leverage [Gradio](https://www.gradio.app/) for creating a user-friendly interface and [Hugging Face Spaces](https://huggingface.co/spaces) for hosting our application.\n",
    "\n",
    "[Groq](groq.com) is known for crazy fast inference speed that is very well-suited for realtime AI applications, providing multiple Large Language Models (LLMs) across various modalities via Groq API. In this tutorial, we will use [LlaVA 1.5 7B](https://huggingface.co/liuhaotian/llava-v1.5-7b) for image analysis and [Llama Guard 3 8B](https://huggingface.co/meta-llama/Llama-Guard-3-8B) for assessing the safety of a given image.\n",
    "\n",
    "## Content Moderation\n",
    "In today's digital age, the internet is a ubiquitous part of our daily lives. However, with the vast amount of information available online, ensuring a safe and positive environment for users has become a significant challenge. This is where content moderation comes into play.\n",
    "\n",
    "Specifically, image moderation is the process of detecting and filtering out inappropriate or harmful images. This is important for maintaining a safe and positive environment for users, especially in applications like online marketplaces, community forums, and social media in general.\n",
    "\n",
    "In this tutorial, we will use the LlaVA model to generate a description of a given image and use the generated description as input for the Llama Guard model to check for conteny safety. LlaVA is a state-of-the-art image understanding model that can answer questions about an image, describe its content, and perform Optical Character Recognition (OCR) to extract text from images. Llama Guard is an advanced content moderation tool designed to assess user messages, or text, for harmful content across 14 categories, including hate speech, threats, and misinformation.\n",
    "\n",
    "Let's dive into the code and learn how to combine the capabilities of Llama Guard and LlaVA to moderate images in real-time!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Create a Free GroqCloud Account and Generate Your Groq API Key\n",
    "\n",
    "If you don't already have a GroqCloud account, you can create one for free [here](https://console.groq.com) to generate a Groq API Key. We'll need the key to be able to try out the tutorial we build! "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Install and Import Required Libraries\n",
    "Let's install and import the libraries we'll need to interact with Groq API and build our image moderation application."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: groq in c:\\users\\admin\\venv\\lib\\site-packages (0.11.0)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in c:\\users\\admin\\venv\\lib\\site-packages (from groq) (4.5.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in c:\\users\\admin\\venv\\lib\\site-packages (from groq) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\admin\\venv\\lib\\site-packages (from groq) (0.27.2)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in c:\\users\\admin\\venv\\lib\\site-packages (from groq) (2.9.2)\n",
      "Requirement already satisfied: sniffio in c:\\users\\admin\\venv\\lib\\site-packages (from groq) (1.3.1)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.7 in c:\\users\\admin\\venv\\lib\\site-packages (from groq) (4.12.2)\n",
      "Requirement already satisfied: idna>=2.8 in c:\\users\\admin\\venv\\lib\\site-packages (from anyio<5,>=3.5.0->groq) (3.10)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in c:\\users\\admin\\venv\\lib\\site-packages (from anyio<5,>=3.5.0->groq) (1.2.2)\n",
      "Requirement already satisfied: certifi in c:\\users\\admin\\venv\\lib\\site-packages (from httpx<1,>=0.23.0->groq) (2024.8.30)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\admin\\venv\\lib\\site-packages (from httpx<1,>=0.23.0->groq) (1.0.6)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\admin\\venv\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->groq) (0.14.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\admin\\venv\\lib\\site-packages (from pydantic<3,>=1.9.0->groq) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.23.4 in c:\\users\\admin\\venv\\lib\\site-packages (from pydantic<3,>=1.9.0->groq) (2.23.4)\n",
      "Collecting gradio\n",
      "  Downloading gradio-4.44.1-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting aiofiles<24.0,>=22.0 (from gradio)\n",
      "  Using cached aiofiles-23.2.1-py3-none-any.whl.metadata (9.7 kB)\n",
      "Requirement already satisfied: anyio<5.0,>=3.0 in c:\\users\\admin\\venv\\lib\\site-packages (from gradio) (4.5.0)\n",
      "Collecting fastapi<1.0 (from gradio)\n",
      "  Downloading fastapi-0.115.2-py3-none-any.whl.metadata (27 kB)\n",
      "Collecting ffmpy (from gradio)\n",
      "  Downloading ffmpy-0.4.0-py3-none-any.whl.metadata (2.9 kB)\n",
      "Collecting gradio-client==1.3.0 (from gradio)\n",
      "  Downloading gradio_client-1.3.0-py3-none-any.whl.metadata (7.1 kB)\n",
      "Requirement already satisfied: httpx>=0.24.1 in c:\\users\\admin\\venv\\lib\\site-packages (from gradio) (0.27.2)\n",
      "Collecting huggingface-hub>=0.19.3 (from gradio)\n",
      "  Downloading huggingface_hub-0.25.2-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting importlib-resources<7.0,>=1.3 (from gradio)\n",
      "  Using cached importlib_resources-6.4.5-py3-none-any.whl.metadata (4.0 kB)\n",
      "Requirement already satisfied: jinja2<4.0 in c:\\users\\admin\\venv\\lib\\site-packages (from gradio) (3.1.4)\n",
      "Requirement already satisfied: markupsafe~=2.0 in c:\\users\\admin\\venv\\lib\\site-packages (from gradio) (2.1.5)\n",
      "Collecting matplotlib~=3.0 (from gradio)\n",
      "  Using cached matplotlib-3.7.5-cp38-cp38-win_amd64.whl.metadata (5.8 kB)\n",
      "Collecting numpy<3.0,>=1.0 (from gradio)\n",
      "  Using cached numpy-1.24.4-cp38-cp38-win_amd64.whl.metadata (5.6 kB)\n",
      "Collecting orjson~=3.0 (from gradio)\n",
      "  Using cached orjson-3.10.7-cp38-none-win_amd64.whl.metadata (51 kB)\n",
      "Requirement already satisfied: packaging in c:\\users\\admin\\venv\\lib\\site-packages (from gradio) (24.1)\n",
      "Collecting pandas<3.0,>=1.0 (from gradio)\n",
      "  Using cached pandas-2.0.3-cp38-cp38-win_amd64.whl.metadata (18 kB)\n",
      "Collecting pillow<11.0,>=8.0 (from gradio)\n",
      "  Using cached pillow-10.4.0-cp38-cp38-win_amd64.whl.metadata (9.3 kB)\n",
      "Requirement already satisfied: pydantic>=2.0 in c:\\users\\admin\\venv\\lib\\site-packages (from gradio) (2.9.2)\n",
      "Collecting pydub (from gradio)\n",
      "  Using cached pydub-0.25.1-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "Collecting python-multipart>=0.0.9 (from gradio)\n",
      "  Using cached python_multipart-0.0.12-py3-none-any.whl.metadata (1.9 kB)\n",
      "Collecting pyyaml<7.0,>=5.0 (from gradio)\n",
      "  Using cached PyYAML-6.0.2-cp38-cp38-win_amd64.whl.metadata (2.1 kB)\n",
      "Collecting ruff>=0.2.2 (from gradio)\n",
      "  Downloading ruff-0.6.9-py3-none-win_amd64.whl.metadata (25 kB)\n",
      "Collecting semantic-version~=2.0 (from gradio)\n",
      "  Using cached semantic_version-2.10.0-py2.py3-none-any.whl.metadata (9.7 kB)\n",
      "Collecting tomlkit==0.12.0 (from gradio)\n",
      "  Using cached tomlkit-0.12.0-py3-none-any.whl.metadata (2.7 kB)\n",
      "Collecting typer<1.0,>=0.12 (from gradio)\n",
      "  Downloading typer-0.12.5-py3-none-any.whl.metadata (15 kB)\n",
      "Requirement already satisfied: typing-extensions~=4.0 in c:\\users\\admin\\venv\\lib\\site-packages (from gradio) (4.12.2)\n",
      "Requirement already satisfied: urllib3~=2.0 in c:\\users\\admin\\venv\\lib\\site-packages (from gradio) (2.2.3)\n",
      "Collecting uvicorn>=0.14.0 (from gradio)\n",
      "  Downloading uvicorn-0.31.1-py3-none-any.whl.metadata (6.6 kB)\n",
      "Collecting fsspec (from gradio-client==1.3.0->gradio)\n",
      "  Using cached fsspec-2024.9.0-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting websockets<13.0,>=10.0 (from gradio-client==1.3.0->gradio)\n",
      "  Using cached websockets-12.0-cp38-cp38-win_amd64.whl.metadata (6.8 kB)\n",
      "Requirement already satisfied: idna>=2.8 in c:\\users\\admin\\venv\\lib\\site-packages (from anyio<5.0,>=3.0->gradio) (3.10)\n",
      "Requirement already satisfied: sniffio>=1.1 in c:\\users\\admin\\venv\\lib\\site-packages (from anyio<5.0,>=3.0->gradio) (1.3.1)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in c:\\users\\admin\\venv\\lib\\site-packages (from anyio<5.0,>=3.0->gradio) (1.2.2)\n",
      "Collecting starlette<0.41.0,>=0.37.2 (from fastapi<1.0->gradio)\n",
      "  Downloading starlette-0.39.2-py3-none-any.whl.metadata (6.0 kB)\n",
      "Requirement already satisfied: certifi in c:\\users\\admin\\venv\\lib\\site-packages (from httpx>=0.24.1->gradio) (2024.8.30)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\admin\\venv\\lib\\site-packages (from httpx>=0.24.1->gradio) (1.0.6)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\admin\\venv\\lib\\site-packages (from httpcore==1.*->httpx>=0.24.1->gradio) (0.14.0)\n",
      "Collecting filelock (from huggingface-hub>=0.19.3->gradio)\n",
      "  Using cached filelock-3.16.1-py3-none-any.whl.metadata (2.9 kB)\n",
      "Requirement already satisfied: requests in c:\\users\\admin\\venv\\lib\\site-packages (from huggingface-hub>=0.19.3->gradio) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in c:\\users\\admin\\venv\\lib\\site-packages (from huggingface-hub>=0.19.3->gradio) (4.66.5)\n",
      "Requirement already satisfied: zipp>=3.1.0 in c:\\users\\admin\\venv\\lib\\site-packages (from importlib-resources<7.0,>=1.3->gradio) (3.20.2)\n",
      "Collecting contourpy>=1.0.1 (from matplotlib~=3.0->gradio)\n",
      "  Using cached contourpy-1.1.1-cp38-cp38-win_amd64.whl.metadata (5.9 kB)\n",
      "Collecting cycler>=0.10 (from matplotlib~=3.0->gradio)\n",
      "  Using cached cycler-0.12.1-py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting fonttools>=4.22.0 (from matplotlib~=3.0->gradio)\n",
      "  Downloading fonttools-4.54.1-cp38-cp38-win_amd64.whl.metadata (167 kB)\n",
      "Collecting kiwisolver>=1.0.1 (from matplotlib~=3.0->gradio)\n",
      "  Using cached kiwisolver-1.4.7-cp38-cp38-win_amd64.whl.metadata (6.4 kB)\n",
      "Collecting pyparsing>=2.3.1 (from matplotlib~=3.0->gradio)\n",
      "  Using cached pyparsing-3.1.4-py3-none-any.whl.metadata (5.1 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\admin\\venv\\lib\\site-packages (from matplotlib~=3.0->gradio) (2.9.0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\admin\\venv\\lib\\site-packages (from pandas<3.0,>=1.0->gradio) (2024.2)\n",
      "Collecting tzdata>=2022.1 (from pandas<3.0,>=1.0->gradio)\n",
      "  Downloading tzdata-2024.2-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\admin\\venv\\lib\\site-packages (from pydantic>=2.0->gradio) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.23.4 in c:\\users\\admin\\venv\\lib\\site-packages (from pydantic>=2.0->gradio) (2.23.4)\n",
      "Requirement already satisfied: click>=8.0.0 in c:\\users\\admin\\venv\\lib\\site-packages (from typer<1.0,>=0.12->gradio) (8.1.7)\n",
      "Collecting shellingham>=1.3.0 (from typer<1.0,>=0.12->gradio)\n",
      "  Using cached shellingham-1.5.4-py2.py3-none-any.whl.metadata (3.5 kB)\n",
      "Collecting rich>=10.11.0 (from typer<1.0,>=0.12->gradio)\n",
      "  Downloading rich-13.9.2-py3-none-any.whl.metadata (18 kB)\n",
      "Requirement already satisfied: colorama in c:\\users\\admin\\venv\\lib\\site-packages (from click>=8.0.0->typer<1.0,>=0.12->gradio) (0.4.6)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\admin\\venv\\lib\\site-packages (from python-dateutil>=2.7->matplotlib~=3.0->gradio) (1.16.0)\n",
      "Collecting markdown-it-py>=2.2.0 (from rich>=10.11.0->typer<1.0,>=0.12->gradio)\n",
      "  Using cached markdown_it_py-3.0.0-py3-none-any.whl.metadata (6.9 kB)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\admin\\venv\\lib\\site-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (2.18.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\admin\\venv\\lib\\site-packages (from requests->huggingface-hub>=0.19.3->gradio) (3.4.0)\n",
      "Collecting mdurl~=0.1 (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.12->gradio)\n",
      "  Using cached mdurl-0.1.2-py3-none-any.whl.metadata (1.6 kB)\n",
      "Downloading gradio-4.44.1-py3-none-any.whl (18.1 MB)\n",
      "   ---------------------------------------- 0.0/18.1 MB ? eta -:--:--\n",
      "    --------------------------------------- 0.3/18.1 MB ? eta -:--:--\n",
      "   - -------------------------------------- 0.5/18.1 MB 1.7 MB/s eta 0:00:11\n",
      "   -- ------------------------------------- 1.0/18.1 MB 2.0 MB/s eta 0:00:09\n",
      "   -- ------------------------------------- 1.3/18.1 MB 2.0 MB/s eta 0:00:09\n",
      "   --- ------------------------------------ 1.6/18.1 MB 1.7 MB/s eta 0:00:10\n",
      "   ---- ----------------------------------- 2.1/18.1 MB 1.8 MB/s eta 0:00:09\n",
      "   ----- ---------------------------------- 2.6/18.1 MB 1.9 MB/s eta 0:00:09\n",
      "   ------ --------------------------------- 3.1/18.1 MB 1.9 MB/s eta 0:00:08\n",
      "   -------- ------------------------------- 3.7/18.1 MB 2.0 MB/s eta 0:00:08\n",
      "   --------- ------------------------------ 4.2/18.1 MB 2.0 MB/s eta 0:00:07\n",
      "   ---------- ----------------------------- 4.7/18.1 MB 2.1 MB/s eta 0:00:07\n",
      "   ----------- ---------------------------- 5.0/18.1 MB 2.1 MB/s eta 0:00:07\n",
      "   ------------ --------------------------- 5.5/18.1 MB 2.1 MB/s eta 0:00:07\n",
      "   ------------ --------------------------- 5.8/18.1 MB 2.0 MB/s eta 0:00:07\n",
      "   ------------- -------------------------- 6.0/18.1 MB 2.0 MB/s eta 0:00:06\n",
      "   -------------- ------------------------- 6.6/18.1 MB 2.0 MB/s eta 0:00:06\n",
      "   --------------- ------------------------ 6.8/18.1 MB 2.0 MB/s eta 0:00:06\n",
      "   ---------------- ----------------------- 7.3/18.1 MB 1.9 MB/s eta 0:00:06\n",
      "   ---------------- ----------------------- 7.6/18.1 MB 1.9 MB/s eta 0:00:06\n",
      "   ----------------- ---------------------- 8.1/18.1 MB 2.0 MB/s eta 0:00:06\n",
      "   ------------------- -------------------- 8.7/18.1 MB 2.0 MB/s eta 0:00:05\n",
      "   ------------------- -------------------- 8.9/18.1 MB 1.9 MB/s eta 0:00:05\n",
      "   -------------------- ------------------- 9.2/18.1 MB 1.9 MB/s eta 0:00:05\n",
      "   -------------------- ------------------- 9.4/18.1 MB 1.9 MB/s eta 0:00:05\n",
      "   ---------------------- ----------------- 10.0/18.1 MB 1.9 MB/s eta 0:00:05\n",
      "   ---------------------- ----------------- 10.2/18.1 MB 1.9 MB/s eta 0:00:05\n",
      "   ----------------------- ---------------- 10.5/18.1 MB 1.9 MB/s eta 0:00:05\n",
      "   ----------------------- ---------------- 10.7/18.1 MB 1.9 MB/s eta 0:00:04\n",
      "   ------------------------ --------------- 11.3/18.1 MB 1.8 MB/s eta 0:00:04\n",
      "   ------------------------- -------------- 11.5/18.1 MB 1.8 MB/s eta 0:00:04\n",
      "   -------------------------- ------------- 12.1/18.1 MB 1.8 MB/s eta 0:00:04\n",
      "   --------------------------- ------------ 12.6/18.1 MB 1.8 MB/s eta 0:00:03\n",
      "   --------------------------- ------------ 12.6/18.1 MB 1.8 MB/s eta 0:00:03\n",
      "   ----------------------------- ---------- 13.1/18.1 MB 1.8 MB/s eta 0:00:03\n",
      "   ----------------------------- ---------- 13.1/18.1 MB 1.8 MB/s eta 0:00:03\n",
      "   ----------------------------- ---------- 13.4/18.1 MB 1.8 MB/s eta 0:00:03\n",
      "   ------------------------------ --------- 13.6/18.1 MB 1.8 MB/s eta 0:00:03\n",
      "   ------------------------------- -------- 14.2/18.1 MB 1.7 MB/s eta 0:00:03\n",
      "   ------------------------------- -------- 14.4/18.1 MB 1.7 MB/s eta 0:00:03\n",
      "   -------------------------------- ------- 14.7/18.1 MB 1.7 MB/s eta 0:00:02\n",
      "   --------------------------------- ------ 15.2/18.1 MB 1.7 MB/s eta 0:00:02\n",
      "   ---------------------------------- ----- 15.5/18.1 MB 1.7 MB/s eta 0:00:02\n",
      "   ----------------------------------- ---- 16.0/18.1 MB 1.7 MB/s eta 0:00:02\n",
      "   ----------------------------------- ---- 16.3/18.1 MB 1.7 MB/s eta 0:00:02\n",
      "   ------------------------------------ --- 16.5/18.1 MB 1.7 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 16.8/18.1 MB 1.7 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 17.0/18.1 MB 1.7 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 17.3/18.1 MB 1.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------  17.8/18.1 MB 1.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 18.1/18.1 MB 1.7 MB/s eta 0:00:00\n",
      "Downloading gradio_client-1.3.0-py3-none-any.whl (318 kB)\n",
      "Using cached tomlkit-0.12.0-py3-none-any.whl (37 kB)\n",
      "Using cached aiofiles-23.2.1-py3-none-any.whl (15 kB)\n",
      "Downloading fastapi-0.115.2-py3-none-any.whl (94 kB)\n",
      "Downloading huggingface_hub-0.25.2-py3-none-any.whl (436 kB)\n",
      "Using cached importlib_resources-6.4.5-py3-none-any.whl (36 kB)\n",
      "Using cached matplotlib-3.7.5-cp38-cp38-win_amd64.whl (7.5 MB)\n",
      "Using cached numpy-1.24.4-cp38-cp38-win_amd64.whl (14.9 MB)\n",
      "Using cached orjson-3.10.7-cp38-none-win_amd64.whl (137 kB)\n",
      "Using cached pandas-2.0.3-cp38-cp38-win_amd64.whl (10.8 MB)\n",
      "Using cached pillow-10.4.0-cp38-cp38-win_amd64.whl (2.6 MB)\n",
      "Using cached python_multipart-0.0.12-py3-none-any.whl (23 kB)\n",
      "Using cached PyYAML-6.0.2-cp38-cp38-win_amd64.whl (162 kB)\n",
      "Downloading ruff-0.6.9-py3-none-win_amd64.whl (9.4 MB)\n",
      "   ---------------------------------------- 0.0/9.4 MB ? eta -:--:--\n",
      "   - -------------------------------------- 0.3/9.4 MB ? eta -:--:--\n",
      "   -- ------------------------------------- 0.5/9.4 MB 1.7 MB/s eta 0:00:06\n",
      "   --- ------------------------------------ 0.8/9.4 MB 1.6 MB/s eta 0:00:06\n",
      "   ----- ---------------------------------- 1.3/9.4 MB 1.6 MB/s eta 0:00:05\n",
      "   ------ --------------------------------- 1.6/9.4 MB 1.6 MB/s eta 0:00:05\n",
      "   -------- ------------------------------- 2.1/9.4 MB 1.7 MB/s eta 0:00:05\n",
      "   ---------- ----------------------------- 2.4/9.4 MB 1.6 MB/s eta 0:00:05\n",
      "   ----------- ---------------------------- 2.6/9.4 MB 1.6 MB/s eta 0:00:05\n",
      "   ------------ --------------------------- 2.9/9.4 MB 1.6 MB/s eta 0:00:04\n",
      "   -------------- ------------------------- 3.4/9.4 MB 1.6 MB/s eta 0:00:04\n",
      "   ---------------- ----------------------- 3.9/9.4 MB 1.7 MB/s eta 0:00:04\n",
      "   ----------------- ---------------------- 4.2/9.4 MB 1.7 MB/s eta 0:00:04\n",
      "   ------------------- -------------------- 4.5/9.4 MB 1.7 MB/s eta 0:00:03\n",
      "   --------------------- ------------------ 5.0/9.4 MB 1.7 MB/s eta 0:00:03\n",
      "   ---------------------- ----------------- 5.2/9.4 MB 1.7 MB/s eta 0:00:03\n",
      "   ------------------------ --------------- 5.8/9.4 MB 1.7 MB/s eta 0:00:03\n",
      "   -------------------------- ------------- 6.3/9.4 MB 1.7 MB/s eta 0:00:02\n",
      "   ---------------------------- ----------- 6.6/9.4 MB 1.8 MB/s eta 0:00:02\n",
      "   ----------------------------- ---------- 6.8/9.4 MB 1.7 MB/s eta 0:00:02\n",
      "   ------------------------------ --------- 7.1/9.4 MB 1.7 MB/s eta 0:00:02\n",
      "   -------------------------------- ------- 7.6/9.4 MB 1.7 MB/s eta 0:00:02\n",
      "   --------------------------------- ------ 7.9/9.4 MB 1.7 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 8.1/9.4 MB 1.7 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 8.7/9.4 MB 1.7 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 8.9/9.4 MB 1.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 9.4/9.4 MB 1.7 MB/s eta 0:00:00\n",
      "Using cached semantic_version-2.10.0-py2.py3-none-any.whl (15 kB)\n",
      "Downloading typer-0.12.5-py3-none-any.whl (47 kB)\n",
      "Downloading uvicorn-0.31.1-py3-none-any.whl (63 kB)\n",
      "Downloading ffmpy-0.4.0-py3-none-any.whl (5.8 kB)\n",
      "Using cached pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n",
      "Using cached contourpy-1.1.1-cp38-cp38-win_amd64.whl (477 kB)\n",
      "Using cached cycler-0.12.1-py3-none-any.whl (8.3 kB)\n",
      "Downloading fonttools-4.54.1-cp38-cp38-win_amd64.whl (1.5 MB)\n",
      "   ---------------------------------------- 0.0/1.5 MB ? eta -:--:--\n",
      "   ------ --------------------------------- 0.3/1.5 MB ? eta -:--:--\n",
      "   -------------------- ------------------- 0.8/1.5 MB 2.1 MB/s eta 0:00:01\n",
      "   --------------------------- ------------ 1.0/1.5 MB 2.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 1.5/1.5 MB 2.0 MB/s eta 0:00:00\n",
      "Using cached fsspec-2024.9.0-py3-none-any.whl (179 kB)\n",
      "Using cached kiwisolver-1.4.7-cp38-cp38-win_amd64.whl (55 kB)\n",
      "Using cached pyparsing-3.1.4-py3-none-any.whl (104 kB)\n",
      "Downloading rich-13.9.2-py3-none-any.whl (242 kB)\n",
      "Using cached shellingham-1.5.4-py2.py3-none-any.whl (9.8 kB)\n",
      "Downloading starlette-0.39.2-py3-none-any.whl (73 kB)\n",
      "Downloading tzdata-2024.2-py2.py3-none-any.whl (346 kB)\n",
      "Using cached websockets-12.0-cp38-cp38-win_amd64.whl (124 kB)\n",
      "Using cached filelock-3.16.1-py3-none-any.whl (16 kB)\n",
      "Using cached markdown_it_py-3.0.0-py3-none-any.whl (87 kB)\n",
      "Using cached mdurl-0.1.2-py3-none-any.whl (10.0 kB)\n",
      "Installing collected packages: pydub, websockets, tzdata, tomlkit, shellingham, semantic-version, ruff, pyyaml, python-multipart, pyparsing, pillow, orjson, numpy, mdurl, kiwisolver, importlib-resources, fsspec, fonttools, filelock, ffmpy, cycler, aiofiles, uvicorn, starlette, pandas, markdown-it-py, huggingface-hub, contourpy, rich, matplotlib, gradio-client, fastapi, typer, gradio\n",
      "Successfully installed aiofiles-23.2.1 contourpy-1.1.1 cycler-0.12.1 fastapi-0.115.2 ffmpy-0.4.0 filelock-3.16.1 fonttools-4.54.1 fsspec-2024.9.0 gradio-4.44.1 gradio-client-1.3.0 huggingface-hub-0.25.2 importlib-resources-6.4.5 kiwisolver-1.4.7 markdown-it-py-3.0.0 matplotlib-3.7.5 mdurl-0.1.2 numpy-1.24.4 orjson-3.10.7 pandas-2.0.3 pillow-10.4.0 pydub-0.25.1 pyparsing-3.1.4 python-multipart-0.0.12 pyyaml-6.0.2 rich-13.9.2 ruff-0.6.9 semantic-version-2.10.0 shellingham-1.5.4 starlette-0.39.2 tomlkit-0.12.0 typer-0.12.5 tzdata-2024.2 uvicorn-0.31.1 websockets-12.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "supervision 0.23.0 requires defusedxml<0.8.0,>=0.7.1, which is not installed.\n",
      "supervision 0.23.0 requires opencv-python-headless>=4.5.5.64, which is not installed.\n",
      "supervision 0.23.0 requires scipy==1.10.0; python_version < \"3.9\", which is not installed.\n",
      "supervision 0.23.0 requires numpy<1.23.3,>=1.21.2; python_full_version <= \"3.10.0\", but you have numpy 1.24.4 which is incompatible.\n",
      "c:\\Users\\Admin\\venv\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "!pip install groq\n",
    "!pip install gradio\n",
    "\n",
    "import base64\n",
    "import io\n",
    "import gradio as gr\n",
    "from groq import Groq\n",
    "from PIL import Image\n",
    "import requests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Implement Image Encoding Function\n",
    "Next, we'll implement a function to encode image inputs to base64 format, which is required by Groq API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_image(image):\n",
    "    buffered = io.BytesIO()\n",
    "    image.save(buffered, format=\"JPEG\")\n",
    "    return base64.b64encode(buffered.getvalue()).decode('utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Implement Image Analysis Function\n",
    "Now let's implement a function that will analyze our input image using the LlaVA model powered by Groq."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_image(image, prompt, api_key, is_url=False):\n",
    "    client = Groq(api_key=api_key)\n",
    "\n",
    "    if is_url:\n",
    "        image_content = {\"type\": \"image_url\", \"image_url\": {\"url\": image}}\n",
    "    else:\n",
    "        base64_image = encode_image(image)\n",
    "        image_content = {\"type\": \"image_url\", \"image_url\": {\"url\": f\"data:image/jpeg;base64,{base64_image}\"}}\n",
    "\n",
    "    try:\n",
    "        chat_completion = client.chat.completions.create(\n",
    "            messages=[\n",
    "                {\n",
    "                    \"role\": \"user\",\n",
    "                    \"content\": [\n",
    "                        {\"type\": \"text\", \"text\": prompt},\n",
    "                        image_content,\n",
    "                    ],\n",
    "                }\n",
    "            ],\n",
    "            model=\"llava-v1.5-7b-4096-preview\",\n",
    "        )\n",
    "        return chat_completion.choices[0].message.content\n",
    "    except Exception as e:\n",
    "        return f\"Error: {str(e)}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Implement Content Safety Check Function\n",
    "Now we'll implement a function to use the Llama Guard model powered by Groq to check the safety of the image by analyzing the image description generated by the LlaVA model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_content_safety(image_description, api_key):\n",
    "    client = Groq(api_key=api_key)\n",
    "\n",
    "    try:\n",
    "        chat_completion = client.chat.completions.create(\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": \"You are a content safety classifier. Analyze the given text and determine if it contains any unsafe or inappropriate content.\"},\n",
    "                {\"role\": \"user\", \"content\": f\"Please analyze this image description for any unsafe or inappropriate content: {image_description}\"}\n",
    "            ],\n",
    "            model=\"llama-guard-3-8b\",\n",
    "        )\n",
    "        return chat_completion.choices[0].message.content\n",
    "    except Exception as e:\n",
    "        return f\"Error: {str(e)}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: Implement Image Processing Function\n",
    "The final function we'll create will handle both uploaded images and image URLs, then call the analysis and safety check functions we built earlier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_image(image, url, prompt, api_key):\n",
    "    if image is not None:\n",
    "        return analyze_image(image, prompt, api_key), check_content_safety(analyze_image(image, prompt, api_key), api_key)\n",
    "    elif url:\n",
    "        try:\n",
    "            response = requests.get(url)\n",
    "            image = Image.open(io.BytesIO(response.content))\n",
    "            return analyze_image(url, prompt, api_key, is_url=True), check_content_safety(analyze_image(url, prompt, api_key, is_url=True), api_key)\n",
    "        except:\n",
    "            return \"Invalid image URL. Please provide a direct link to an image.\", \"\"\n",
    "    else:\n",
    "        return \"Please provide an image to analyze.\", \"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 7: Create Gradio Interface and Launch Application\n",
    "Now we'll use Gradio components to build out a simple user interface and launch our image moderation application!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7860\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7860/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Admin\\venv\\lib\\site-packages\\gradio\\analytics.py:106: UserWarning: IMPORTANT: You are using gradio version 4.44.1, however version 5.0.1 is available, please upgrade. \n",
      "--------\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "def launch():\n",
    "    with gr.Blocks(\n",
    "        theme=gr.themes.Default(primary_hue=\"orange\"),\n",
    "        css=\"\"\"\n",
    "        #app-container { max-width: 1000px; margin: auto; padding: 10px; }\n",
    "        #title { text-align: center; margin-bottom: 10px; font-size: 24px; }\n",
    "        #groq-badge { text-align: center; margin-top: 10px; }\n",
    "        .gr-button { border-radius: 15px; }\n",
    "        .gr-input, .gr-box { border-radius: 10px; }\n",
    "        .gr-form { gap: 5px; }\n",
    "        .gr-block.gr-box { padding: 10px; }\n",
    "        .gr-paddle { height: auto; }\n",
    "        \"\"\"\n",
    "    ) as demo:\n",
    "        with gr.Column(elem_id=\"app-container\"):\n",
    "            gr.Markdown(\"# 🖼️ Groq x Gradio Image Analysis and Content Safety Check\", elem_id=\"title\")\n",
    "            \n",
    "            with gr.Row():\n",
    "                api_key = gr.Textbox(label=\"Groq API Key:\", type=\"password\", scale=2)\n",
    "                prompt = gr.Textbox(\n",
    "                    label=\"Image Analysis Prompt:\",\n",
    "                    value=\"Describe the image content.\",\n",
    "                    scale=3\n",
    "                )\n",
    "            \n",
    "            with gr.Row():\n",
    "                with gr.Column(scale=1):\n",
    "                    image_input = gr.Image(type=\"pil\", label=\"Upload Image:\", height=200, sources=[\"upload\"])\n",
    "                with gr.Column(scale=1):\n",
    "                    url_input = gr.Textbox(label=\"Or Paste Image URL:\", lines=1)\n",
    "                    analyze_button = gr.Button(\"🚀 Analyze Image\", variant=\"primary\")\n",
    "            \n",
    "            with gr.Row():\n",
    "                with gr.Column():\n",
    "                    analysis_output = gr.Textbox(label=\"Image Analysis with LlaVA 1.5 7B:\", lines=6)\n",
    "                with gr.Column():\n",
    "                    safety_output = gr.Textbox(label=\"Safety Check with Llama Guard 3 8B:\", lines=6)\n",
    "            \n",
    "            analyze_button.click(\n",
    "                fn=process_image,\n",
    "                inputs=[image_input, url_input, prompt, api_key],\n",
    "                outputs=[analysis_output, safety_output]\n",
    "            )\n",
    "            \n",
    "            with gr.Row():\n",
    "                with gr.Column():\n",
    "                    gr.HTML(\"\"\"\n",
    "                    <div id=\"groq-badge\">\n",
    "                        <div style=\"color: #f55036; font-weight: bold; font-size: 1em;\">⚡ POWERED BY GROQ ⚡</div>\n",
    "                    </div>\n",
    "                    \"\"\")\n",
    "                    \n",
    "                with gr.Column():\n",
    "                    gr.Markdown(\"\"\"\n",
    "                    **How to use this app:** \n",
    "                    1. Enter your [Groq API Key](https://console.groq.com/keys) in the provided field.\n",
    "                    2. Upload an image file or paste an image URL.\n",
    "                    3. Use default prompt or enter custom prompt for image analysis.\n",
    "                    4. Click \"Analyze Image\" to check for content safety.\n",
    "                    \"\"\")\n",
    "    \n",
    "    demo.launch()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    launch()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (Optional) Step 8: Host on Hugging Face Spaces\n",
    "If you don't already have one, create a free Hugging Face account [here](https://huggingface.co/join). To deploy our app to Hugging Face Spaces from our browser, all we have to do is drag and drop all related files [here](https://huggingface.co/new-space). In this case, we'll create an `app.py` file as well as a `requirements.txt` file. \n",
    "\n",
    "In the `app.py` file, simply copy-paste the above code and feel free to modify for additional features or a different look! \n",
    "\n",
    "In the `requirements.txt` file, add in the required dependencies for Hugging Face Spaces to detect and automatically install before deploying our application to a public link that anyone can access.\n",
    "\n",
    "For this project, the following dependencies were added to the `requirements.txt` file:\n",
    "\n",
    "```\n",
    "groq\n",
    "gradio\n",
    "```\n",
    "\n",
    "Once the required application files are added, Hugging Face Spaces will automatically detect, build, run, and deploy our application! You can see and try this tutorial live [here](https://huggingface.co/spaces/Groq/image-moderation)! 😁\n",
    "\n",
    "# Conclusion\n",
    "By combining Groq, Gradio, and Hugging Face Spaces, we've created and deployed a powerful and easy-to-use image moderation tool.\n",
    "\n",
    "We hope you found this tutorial helpful and that you'll use it to create your own image moderation tools and applications. Feel free to experiment with this code and extend the functionality to create your own personal project! Happy building! 🤩"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
