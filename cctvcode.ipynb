{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "while True:\n",
    "   ret, frame = cap.read()\n",
    "   cv2.imshow('frame', frame)\n",
    "   if cv2.waitKey(1) == ord('q'):\n",
    "         break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### access cctv camera\n",
    "#### single cctv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "cap = cv2.VideoCapture('rtsp://admin:hik12345@10.199.27.123:554')\n",
    "while True:\n",
    "    ret, img = cap.read()\n",
    "    cv2.imshow('video output', img)\n",
    "    k = cv2.waitKey(10)& 0xff\n",
    "    if k == 27:\n",
    "        break\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### multiple cctv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "# List of camera RTSP streams (replace with actual camera credentials and IP addresses)\n",
    "camera_streams = [\n",
    "    'rtsp://admin:hik12345@10.199.27.123:554',\n",
    "    'rtsp://admin:hik12345@10.199.27.124:554',\n",
    "    'rtsp://admin:hik12345@10.199.27.125:554'\n",
    "]\n",
    "\n",
    "# Open video captures for all cameras\n",
    "caps = [cv2.VideoCapture(stream) for stream in camera_streams]\n",
    "\n",
    "# Check if all cameras opened successfully\n",
    "for i, cap in enumerate(caps):\n",
    "    if not cap.isOpened():\n",
    "        print(f\"Error: Couldn't open video stream {i+1}\")\n",
    "        caps[i] = None  # Mark this capture as invalid\n",
    "\n",
    "while True:\n",
    "    for i, cap in enumerate(caps):\n",
    "        if cap is None:  # Skip invalid cameras\n",
    "            continue\n",
    "\n",
    "        ret, img = cap.read()\n",
    "        if not ret:\n",
    "            print(f\"Error: Couldn't read frame from camera {i+1}\")\n",
    "            continue\n",
    "\n",
    "        # Display the frame in a window named after the camera number\n",
    "        cv2.imshow(f'Camera {i+1} Output', img)\n",
    "\n",
    "    # Break loop and close all windows if 'ESC' key is pressed\n",
    "    if cv2.waitKey(10) & 0xFF == 27:  # ESC key\n",
    "        break\n",
    "\n",
    "# Release all camera captures and close windows\n",
    "for cap in caps:\n",
    "    if cap is not None:\n",
    "        cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### method 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "cap = cv2.VideoCapture()\n",
    "cap.open(\"rtsp://yourusername:yourpassword@172.16.30.248:555/Streaming/channels/2/\")\n",
    "\n",
    "while(True):\n",
    "     # Capture frame-by-frame\n",
    "    ret, frame = cap.read()\n",
    "\n",
    "    # Our operations on the frame come here\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Display the resulting frame\n",
    "    # cv2.imshow('frame',ret)\n",
    "    cv2.imshow('frame',frame)\n",
    "\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# When everything done, release the capture\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Inference on webcam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting real-time object detection... Press 'q' to exit.\n",
      "\n",
      "0: 480x640 (no detections), 860.8ms\n",
      "Speed: 2.1ms preprocess, 860.8ms inference, 6.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 742.2ms\n",
      "Speed: 3.2ms preprocess, 742.2ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 905.8ms\n",
      "Speed: 3.0ms preprocess, 905.8ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 972.3ms\n",
      "Speed: 2.2ms preprocess, 972.3ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 895.4ms\n",
      "Speed: 3.0ms preprocess, 895.4ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 1034.4ms\n",
      "Speed: 3.2ms preprocess, 1034.4ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 1258.9ms\n",
      "Speed: 2.0ms preprocess, 1258.9ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 1044.7ms\n",
      "Speed: 3.0ms preprocess, 1044.7ms inference, 1.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 1241.3ms\n",
      "Speed: 2.0ms preprocess, 1241.3ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 1244.0ms\n",
      "Speed: 2.0ms preprocess, 1244.0ms inference, 2.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 1268.7ms\n",
      "Speed: 34.8ms preprocess, 1268.7ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 1332.3ms\n",
      "Speed: 3.3ms preprocess, 1332.3ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 942.4ms\n",
      "Speed: 3.0ms preprocess, 942.4ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 931.0ms\n",
      "Speed: 3.2ms preprocess, 931.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 1264.1ms\n",
      "Speed: 3.0ms preprocess, 1264.1ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Hardhat, 1 NO-Mask, 1 Person, 1 Safety Vest, 1117.3ms\n",
      "Speed: 4.0ms preprocess, 1117.3ms inference, 9.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Hardhat, 1 NO-Mask, 1 Person, 1 Safety Vest, 1369.2ms\n",
      "Speed: 4.0ms preprocess, 1369.2ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Hardhat, 1 NO-Mask, 1 Person, 1 Safety Vest, 1151.4ms\n",
      "Speed: 3.0ms preprocess, 1151.4ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Hardhat, 1 NO-Mask, 1 Person, 1 Safety Vest, 1355.2ms\n",
      "Speed: 4.0ms preprocess, 1355.2ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Hardhat, 1 NO-Mask, 1 Person, 1 Safety Vest, 1071.5ms\n",
      "Speed: 3.2ms preprocess, 1071.5ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Hardhat, 1 NO-Mask, 1 Person, 1 Safety Vest, 1144.7ms\n",
      "Speed: 3.0ms preprocess, 1144.7ms inference, 2.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Hardhat, 1 NO-Mask, 1 Person, 1 Safety Vest, 1271.2ms\n",
      "Speed: 4.4ms preprocess, 1271.2ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Hardhat, 1 NO-Mask, 1 Person, 1 Safety Vest, 1204.6ms\n",
      "Speed: 0.8ms preprocess, 1204.6ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Hardhat, 1 NO-Mask, 1 Person, 1 Safety Vest, 1259.1ms\n",
      "Speed: 3.0ms preprocess, 1259.1ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Hardhat, 1 NO-Mask, 1 Person, 1 Safety Vest, 1124.2ms\n",
      "Speed: 3.0ms preprocess, 1124.2ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Hardhat, 1 NO-Mask, 1 Person, 1 Safety Vest, 1227.8ms\n",
      "Speed: 3.0ms preprocess, 1227.8ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Hardhat, 1 NO-Mask, 1 Person, 1 Safety Vest, 1137.8ms\n",
      "Speed: 4.0ms preprocess, 1137.8ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Hardhat, 1 NO-Mask, 1 Person, 1 Safety Vest, 1311.4ms\n",
      "Speed: 3.0ms preprocess, 1311.4ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Hardhat, 1 NO-Mask, 1 Person, 1 Safety Vest, 1413.2ms\n",
      "Speed: 3.0ms preprocess, 1413.2ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Hardhat, 1 NO-Mask, 1 Person, 1 Safety Vest, 1202.6ms\n",
      "Speed: 3.0ms preprocess, 1202.6ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Hardhat, 1 NO-Mask, 1 Person, 1 Safety Vest, 1297.0ms\n",
      "Speed: 2.1ms preprocess, 1297.0ms inference, 2.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Hardhat, 1 NO-Mask, 1 Person, 1 Safety Vest, 1221.2ms\n",
      "Speed: 3.0ms preprocess, 1221.2ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Hardhat, 1 NO-Mask, 1 Person, 1 Safety Vest, 1234.2ms\n",
      "Speed: 3.0ms preprocess, 1234.2ms inference, 2.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Hardhat, 1 NO-Mask, 1 Person, 1 Safety Vest, 1173.9ms\n",
      "Speed: 3.0ms preprocess, 1173.9ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Hardhat, 1 NO-Mask, 1 Person, 1 Safety Vest, 1262.1ms\n",
      "Speed: 3.0ms preprocess, 1262.1ms inference, 2.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Hardhat, 1 NO-Mask, 1 Person, 1 Safety Vest, 1190.2ms\n",
      "Speed: 3.1ms preprocess, 1190.2ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Hardhat, 1 NO-Mask, 1 Person, 1 Safety Vest, 1137.3ms\n",
      "Speed: 4.0ms preprocess, 1137.3ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Hardhat, 1 NO-Mask, 1 Person, 1 Safety Vest, 1217.6ms\n",
      "Speed: 3.0ms preprocess, 1217.6ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Hardhat, 1 NO-Mask, 1 Person, 1 Safety Vest, 1183.4ms\n",
      "Speed: 4.0ms preprocess, 1183.4ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Hardhat, 1 NO-Mask, 2 Persons, 1 Safety Vest, 1280.4ms\n",
      "Speed: 4.0ms preprocess, 1280.4ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Hardhat, 1 NO-Mask, 1 Person, 1 Safety Vest, 1131.5ms\n",
      "Speed: 3.0ms preprocess, 1131.5ms inference, 2.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Hardhat, 1 NO-Mask, 1 Person, 1 Safety Vest, 1263.0ms\n",
      "Speed: 5.0ms preprocess, 1263.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Hardhat, 1 NO-Mask, 1 Person, 1 Safety Vest, 1242.3ms\n",
      "Speed: 4.1ms preprocess, 1242.3ms inference, 3.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Hardhat, 1 NO-Mask, 2 Persons, 1 Safety Vest, 1232.3ms\n",
      "Speed: 3.0ms preprocess, 1232.3ms inference, 2.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Hardhat, 1 NO-Mask, 1 Person, 1 Safety Vest, 1252.6ms\n",
      "Speed: 3.0ms preprocess, 1252.6ms inference, 2.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Hardhat, 1 NO-Mask, 1 Person, 1 Safety Vest, 1324.1ms\n",
      "Speed: 3.0ms preprocess, 1324.1ms inference, 2.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Hardhat, 1 NO-Mask, 1 Person, 1 Safety Vest, 1368.4ms\n",
      "Speed: 11.0ms preprocess, 1368.4ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Hardhat, 1 NO-Mask, 1 Person, 1 Safety Vest, 1164.1ms\n",
      "Speed: 3.0ms preprocess, 1164.1ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Hardhat, 1 NO-Mask, 1 Person, 1 Safety Vest, 1276.9ms\n",
      "Speed: 4.0ms preprocess, 1276.9ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Hardhat, 1 NO-Mask, 1 Person, 1 Safety Vest, 1173.8ms\n",
      "Speed: 4.0ms preprocess, 1173.8ms inference, 2.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Hardhat, 1 NO-Mask, 1 Person, 1 Safety Vest, 1228.8ms\n",
      "Speed: 3.0ms preprocess, 1228.8ms inference, 2.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Hardhat, 1 NO-Mask, 2 Persons, 1 Safety Vest, 1237.4ms\n",
      "Speed: 3.1ms preprocess, 1237.4ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 NO-Mask, 2 Persons, 1 Safety Vest, 1040.6ms\n",
      "Speed: 3.3ms preprocess, 1040.6ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 NO-Mask, 2 Persons, 1 Safety Vest, 1202.0ms\n",
      "Speed: 4.0ms preprocess, 1202.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 NO-Mask, 3 Persons, 1 Safety Vest, 1090.9ms\n",
      "Speed: 3.0ms preprocess, 1090.9ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 NO-Mask, 2 Persons, 1 Safety Vest, 1300.8ms\n",
      "Speed: 3.4ms preprocess, 1300.8ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 NO-Mask, 2 Persons, 1 Safety Vest, 1270.4ms\n",
      "Speed: 3.3ms preprocess, 1270.4ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Hardhat, 1 NO-Mask, 1 Person, 1 Safety Vest, 1396.6ms\n",
      "Speed: 3.1ms preprocess, 1396.6ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Hardhat, 1 NO-Mask, 1 Person, 1 Safety Vest, 1190.9ms\n",
      "Speed: 4.0ms preprocess, 1190.9ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Hardhat, 1 NO-Mask, 1 Person, 1 Safety Vest, 1158.4ms\n",
      "Speed: 3.2ms preprocess, 1158.4ms inference, 2.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Hardhat, 1 NO-Mask, 1 Person, 1 Safety Vest, 1157.8ms\n",
      "Speed: 3.4ms preprocess, 1157.8ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Hardhat, 1 NO-Mask, 1 Person, 1 Safety Vest, 1122.7ms\n",
      "Speed: 4.0ms preprocess, 1122.7ms inference, 3.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Hardhat, 1 NO-Mask, 1 Person, 1 Safety Vest, 1216.3ms\n",
      "Speed: 2.6ms preprocess, 1216.3ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Hardhat, 1 NO-Mask, 1 Person, 1 Safety Vest, 1154.2ms\n",
      "Speed: 4.0ms preprocess, 1154.2ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Hardhat, 1 NO-Mask, 1 Person, 1 Safety Vest, 1264.7ms\n",
      "Speed: 4.0ms preprocess, 1264.7ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Hardhat, 1 NO-Mask, 1 Person, 1 Safety Vest, 1147.2ms\n",
      "Speed: 4.0ms preprocess, 1147.2ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Hardhat, 1 NO-Mask, 1 Person, 1 Safety Vest, 1270.6ms\n",
      "Speed: 4.1ms preprocess, 1270.6ms inference, 1.1ms postprocess per image at shape (1, 3, 480, 640)\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "from ultralytics import YOLO\n",
    "\n",
    "# Path to your YOLOv8 model file\n",
    "model_path = r'C:\\Users\\Admin\\Documents\\vs python\\YOLOv8-MODEL\\weights\\best.pt'\n",
    "model = YOLO(model_path)\n",
    "\n",
    "def process_frame(frame):\n",
    "    # Perform detection\n",
    "    results = model(frame)[0]  # Get the first result from the list\n",
    "    # Draw results on the frame using the plot method\n",
    "    annotated_frame = results.plot()\n",
    "    return annotated_frame\n",
    "\n",
    "def main():\n",
    "    # Initialize video capture for the default webcam (index 0)\n",
    "    cap = cv2.VideoCapture(0)\n",
    "\n",
    "    if not cap.isOpened():\n",
    "        print(\"Error: Couldn't open webcam.\")\n",
    "        return\n",
    "\n",
    "    print(\"Starting real-time object detection... Press 'q' to exit.\")\n",
    "    \n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            print(\"Error: Couldn't read frame from webcam.\")\n",
    "            break\n",
    "        \n",
    "        # Process the frame with YOLOv8\n",
    "        annotated_frame = process_frame(frame)\n",
    "        \n",
    "        # Display the resulting frame\n",
    "        cv2.imshow('YOLOv8 Detection', annotated_frame)\n",
    "        \n",
    "        # Exit if 'q' key is pressed\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "    # Release resources\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Access cameras\n",
    "#### Single camera"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "# Replace with your CCTV stream URL\n",
    "cctv_url = \"http://username:password@your-cctv-ip-address:port/stream\"\n",
    "\n",
    "def main():\n",
    "    # Initialize video capture from CCTV stream\n",
    "    cap = cv2.VideoCapture(cctv_url)\n",
    "\n",
    "    if not cap.isOpened():\n",
    "        print(\"Error: Couldn't open video stream.\")\n",
    "        return\n",
    "\n",
    "    print(\"Accessing CCTV stream... Press 'q' to exit.\")\n",
    "    \n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            print(\"Error: Couldn't read frame.\")\n",
    "            break\n",
    "        \n",
    "        # Display the frame\n",
    "        cv2.imshow('CCTV Stream', frame)\n",
    "        \n",
    "        # Exit if 'q' key is pressed\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "    # Release resources\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Multiple cameras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# List of CCTV stream URLs (with authentication if required)\n",
    "cctv_urls = [\n",
    "    \"http://username1:password1@your-cctv-ip-address1:port/stream\",\n",
    "    \"http://username2:password2@your-cctv-ip-address2:port/stream\",\n",
    "    \"http://username3:password3@your-cctv-ip-address3:port/stream\"  # Add more URLs as needed\n",
    "]\n",
    "\n",
    "def main():\n",
    "    # Initialize video captures for all CCTV streams\n",
    "    caps = [cv2.VideoCapture(url) for url in cctv_urls]\n",
    "\n",
    "    if not all([cap.isOpened() for cap in caps]):\n",
    "        print(\"Error: Couldn't open one or more video streams.\")\n",
    "        return\n",
    "\n",
    "    print(\"Accessing multiple CCTV streams... Press 'q' to exit.\")\n",
    "    \n",
    "    while True:\n",
    "        frames = []\n",
    "        for cap in caps:\n",
    "            ret, frame = cap.read()\n",
    "            if not ret:\n",
    "                print(\"Error: Couldn't read frame.\")\n",
    "                break\n",
    "            frames.append(frame)\n",
    "\n",
    "        # Exit if no frames are returned (meaning one or more streams failed)\n",
    "        if not frames:\n",
    "            break\n",
    "\n",
    "        # Display the frames in a grid layout\n",
    "        # Adjust grid layout based on the number of cameras\n",
    "        grid_rows = int(np.ceil(len(frames) / 2))\n",
    "        grid_cols = min(2, len(frames))\n",
    "\n",
    "        # Rescale frames for uniform size\n",
    "        frame_height, frame_width = frames[0].shape[:2]\n",
    "        new_height, new_width = frame_height // 2, frame_width // 2  # Resize to half for grid\n",
    "\n",
    "        resized_frames = [cv2.resize(frame, (new_width, new_height)) for frame in frames]\n",
    "\n",
    "        # Combine frames row-wise\n",
    "        frame_rows = []\n",
    "        for i in range(0, len(resized_frames), grid_cols):\n",
    "            row = np.hstack(resized_frames[i:i+grid_cols])\n",
    "            frame_rows.append(row)\n",
    "\n",
    "        # Combine all rows into the final grid display\n",
    "        output_frame = np.vstack(frame_rows)\n",
    "\n",
    "        # Display the grid\n",
    "        cv2.imshow('Multiple CCTV Streams', output_frame)\n",
    "\n",
    "        # Exit if 'q' key is pressed\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "    # Release all resources\n",
    "    for cap in caps:\n",
    "        cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Detection\n",
    "#### Single Camera"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "from ultralytics import YOLO\n",
    "\n",
    "# Replace with your CCTV stream URL\n",
    "cctv_url = \"http://your-cctv-ip-address:port/stream\"\n",
    "\n",
    "# Load the YOLOv8 model\n",
    "model_path = r'C:\\Users\\Admin\\Documents\\vs python\\YOLOv8-MODEL\\weights\\best.pt'\n",
    "model = YOLO(model_path)\n",
    "\n",
    "def process_frame(frame):\n",
    "    # Perform detection\n",
    "    results = model(frame)[0]  # Get the first result from the list\n",
    "    # Draw results on the frame using the plot method\n",
    "    annotated_frame = results.plot()\n",
    "    return annotated_frame\n",
    "\n",
    "def main():\n",
    "    # Initialize video capture from CCTV stream\n",
    "    cap = cv2.VideoCapture(cctv_url)\n",
    "\n",
    "    if not cap.isOpened():\n",
    "        print(\"Error: Couldn't open video stream.\")\n",
    "        return\n",
    "\n",
    "    print(\"Starting real-time object detection... Press 'q' to exit.\")\n",
    "    \n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            print(\"Error: Couldn't read frame.\")\n",
    "            break\n",
    "        \n",
    "        # Process the frame with YOLOv8\n",
    "        annotated_frame = process_frame(frame)\n",
    "        \n",
    "        # Display the resulting frame\n",
    "        cv2.imshow('YOLOv8 Detection', annotated_frame)\n",
    "        \n",
    "        # Exit if 'q' key is pressed\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "    # Release resources\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Multiple Cameras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "from ultralytics import YOLO\n",
    "import numpy as np\n",
    "\n",
    "# List of CCTV stream URLs\n",
    "cctv_urls = [\n",
    "    \"http://your-cctv-ip-address1:port/stream\",\n",
    "    \"http://your-cctv-ip-address2:port/stream\",\n",
    "    \"http://your-cctv-ip-address3:port/stream\"  # Add more URLs as needed\n",
    "]\n",
    "\n",
    "# Load the YOLOv8 model\n",
    "model_path = r'C:\\Users\\Admin\\Documents\\vs python\\YOLOv8-MODEL\\weights\\best.pt'\n",
    "model = YOLO(model_path)\n",
    "\n",
    "def process_frame(frame):\n",
    "    # Perform detection\n",
    "    results = model(frame)[0]  # Get the first result from the list\n",
    "    # Draw results on the frame using the plot method\n",
    "    annotated_frame = results.plot()\n",
    "    return annotated_frame\n",
    "\n",
    "def main():\n",
    "    # Initialize video captures for all CCTV streams\n",
    "    caps = [cv2.VideoCapture(url) for url in cctv_urls]\n",
    "\n",
    "    if not all([cap.isOpened() for cap in caps]):\n",
    "        print(\"Error: Couldn't open one or more video streams.\")\n",
    "        return\n",
    "\n",
    "    print(\"Starting real-time object detection... Press 'q' to exit.\")\n",
    "\n",
    "    while True:\n",
    "        frames = []\n",
    "        for cap in caps:\n",
    "            ret, frame = cap.read()\n",
    "            if not ret:\n",
    "                print(\"Error: Couldn't read frame.\")\n",
    "                break\n",
    "            # Process the frame with YOLOv8\n",
    "            annotated_frame = process_frame(frame)\n",
    "            frames.append(annotated_frame)\n",
    "\n",
    "        # Exit if no frames are returned (meaning one or more streams failed)\n",
    "        if not frames:\n",
    "            break\n",
    "        \n",
    "        # Display the resulting frames\n",
    "        # Combine the frames into a grid depending on the number of cameras\n",
    "        # For simplicity, this assumes 2x2 grid for 4 cameras (can be modified for more)\n",
    "        grid_rows = int(np.ceil(len(frames) / 2))\n",
    "        grid_cols = min(2, len(frames))\n",
    "\n",
    "        # Rescale frames for uniform size\n",
    "        frame_height, frame_width = frames[0].shape[:2]\n",
    "        new_height, new_width = frame_height // 2, frame_width // 2  # Resize to half for grid\n",
    "\n",
    "        resized_frames = [cv2.resize(frame, (new_width, new_height)) for frame in frames]\n",
    "\n",
    "        # Combine frames row-wise\n",
    "        frame_rows = []\n",
    "        for i in range(0, len(resized_frames), grid_cols):\n",
    "            row = np.hstack(resized_frames[i:i+grid_cols])\n",
    "            frame_rows.append(row)\n",
    "\n",
    "        # Combine all rows into the final grid display\n",
    "        output_frame = np.vstack(frame_rows)\n",
    "\n",
    "        # Display the grid\n",
    "        cv2.imshow('YOLOv8 Detection from Multiple Cameras', output_frame)\n",
    "\n",
    "        # Exit if 'q' key is pressed\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "    # Release all resources\n",
    "    for cap in caps:\n",
    "        cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### With Passwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "from ultralytics import YOLO\n",
    "import numpy as np\n",
    "\n",
    "# List of CCTV stream URLs (with authentication)\n",
    "cctv_urls = [\n",
    "    \"http://username1:password1@your-cctv-ip-address1:port/stream\",\n",
    "    \"http://username2:password2@your-cctv-ip-address2:port/stream\",\n",
    "    \"http://username3:password3@your-cctv-ip-address3:port/stream\"  # Add more URLs as needed\n",
    "]\n",
    "\n",
    "# Load the YOLOv8 model\n",
    "model_path = r'C:\\Users\\Admin\\Documents\\vs python\\YOLOv8-MODEL\\weights\\best.pt'\n",
    "model = YOLO(model_path)\n",
    "\n",
    "def process_frame(frame):\n",
    "    # Perform detection\n",
    "    results = model(frame)[0]  # Get the first result from the list\n",
    "    # Draw results on the frame using the plot method\n",
    "    annotated_frame = results.plot()\n",
    "    return annotated_frame\n",
    "\n",
    "def main():\n",
    "    # Initialize video captures for all CCTV streams\n",
    "    caps = [cv2.VideoCapture(url) for url in cctv_urls]\n",
    "\n",
    "    if not all([cap.isOpened() for cap in caps]):\n",
    "        print(\"Error: Couldn't open one or more video streams.\")\n",
    "        return\n",
    "\n",
    "    print(\"Starting real-time object detection... Press 'q' to exit.\")\n",
    "\n",
    "    while True:\n",
    "        frames = []\n",
    "        for cap in caps:\n",
    "            ret, frame = cap.read()\n",
    "            if not ret:\n",
    "                print(\"Error: Couldn't read frame.\")\n",
    "                break\n",
    "            # Process the frame with YOLOv8\n",
    "            annotated_frame = process_frame(frame)\n",
    "            frames.append(annotated_frame)\n",
    "\n",
    "        # Exit if no frames are returned (meaning one or more streams failed)\n",
    "        if not frames:\n",
    "            break\n",
    "        \n",
    "        # Display the resulting frames\n",
    "        # Combine the frames into a grid depending on the number of cameras\n",
    "        grid_rows = int(np.ceil(len(frames) / 2))\n",
    "        grid_cols = min(2, len(frames))\n",
    "\n",
    "        # Rescale frames for uniform size\n",
    "        frame_height, frame_width = frames[0].shape[:2]\n",
    "        new_height, new_width = frame_height // 2, frame_width // 2  # Resize to half for grid\n",
    "\n",
    "        resized_frames = [cv2.resize(frame, (new_width, new_height)) for frame in frames]\n",
    "\n",
    "        # Combine frames row-wise\n",
    "        frame_rows = []\n",
    "        for i in range(0, len(resized_frames), grid_cols):\n",
    "            row = np.hstack(resized_frames[i:i+grid_cols])\n",
    "            frame_rows.append(row)\n",
    "\n",
    "        # Combine all rows into the final grid display\n",
    "        output_frame = np.vstack(frame_rows)\n",
    "\n",
    "        # Display the grid\n",
    "        cv2.imshow('YOLOv8 Detection from Multiple Cameras', output_frame)\n",
    "\n",
    "        # Exit if 'q' key is pressed\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "    # Release all resources\n",
    "    for cap in caps:\n",
    "        cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\"http://username:password@your-cctv-ip-address:port/stream\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
